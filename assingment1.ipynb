{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assingment1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX9Zmz5ByyUn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import nn,functional\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq2brG2RO9nF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batch_size =107\n",
        "test_batch_size =107\n",
        "train = pd.read_csv(\"fashion-mnist_train.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-r2Y04LW9-Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = train.loc[:,train.columns != \"label\"].values/255   #Normalizing the values\n",
        "Y = train.label.values\n",
        "\n",
        "features_train, features_test, targets_train, targets_test = train_test_split(X,Y,test_size=0.2,\n",
        "                                                                              random_state=42)\n",
        "X_train = torch.from_numpy(features_train)\n",
        "X_test = torch.from_numpy(features_test)\n",
        "\n",
        "Y_train = torch.from_numpy(targets_train).type(torch.LongTensor) \n",
        "Y_test = torch.from_numpy(targets_test).type(torch.LongTensor)\n",
        "\n",
        "train = torch.utils.data.TensorDataset(X_train,Y_train)\n",
        "test = torch.utils.data.TensorDataset(X_test,Y_test)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size = train_batch_size, shuffle = False)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size = test_batch_size, shuffle = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlU8f57JXVAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        \n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        \n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        \n",
        "        self.fc1 = nn.Linear(in_features=64*6*6, out_features=600)\n",
        "        self.drop = nn.Dropout2d(0.25)\n",
        "        self.fc2 = nn.Linear(in_features=600, out_features=120)\n",
        "        self.fc3 = nn.Linear(in_features=120, out_features=10)\n",
        "  def forward(self, x):\n",
        "    out = self.layer1(x)\n",
        "    out = self.layer2(out)\n",
        "    out = out.view(out.size(0), -1)\n",
        "    out = self.fc1(out)\n",
        "    out = self.drop(out)\n",
        "    out = self.fc2(out)\n",
        "    out = self.fc3(out)\n",
        "    \n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4K7Mr9TQbUQC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = CNN()\n",
        "model = model.double()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr=3e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwKNNH3kvcRQ",
        "colab_type": "code",
        "outputId": "4c7a8eba-b6cc-44de-fc23-429b295e1a7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "epochs = 15\n",
        "train_losses, test_losses = [] ,[]\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images,labels in train_loader:\n",
        "        train = Variable(images.view(-1,1,28,28))\n",
        "        labels = Variable(labels)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(train)\n",
        "        loss = criterion(output,labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        test_loss = 0\n",
        "        accuracy = 0\n",
        "        \n",
        "        with torch.no_grad(): #Turning off gradients to speed up\n",
        "            model.eval()\n",
        "            for images,labels in test_loader:\n",
        "                \n",
        "                test = Variable(images.view(-1,1,28,28))\n",
        "                labels = Variable(labels)\n",
        "                \n",
        "                log_ps = model(test)\n",
        "                test_loss += criterion(log_ps,labels)\n",
        "                \n",
        "                ps = torch.exp(log_ps)\n",
        "                top_p, top_class = ps.topk(1, dim = 1)\n",
        "                equals = top_class == labels.view(*top_class.shape)\n",
        "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
        "        model.train()        \n",
        "        train_losses.append(running_loss/len(train_loader))\n",
        "        test_losses.append(test_loss/len(test_loader))\n",
        "\n",
        "        print(\"Epoch: {}/{}.. \".format(epoch+1, epochs),\n",
        "              \"Training Loss: {:.3f}.. \".format(running_loss/len(train_loader)),\n",
        "              \"Test Loss: {:.3f}.. \".format(test_loss/len(test_loader)),\n",
        "              \"Test Accuracy: {:.3f}\".format(accuracy/len(test_loader)))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/15..  Training Loss: 0.441..  Test Loss: 0.381..  Test Accuracy: 0.861\n",
            "Epoch: 2/15..  Training Loss: 0.306..  Test Loss: 0.297..  Test Accuracy: 0.896\n",
            "Epoch: 3/15..  Training Loss: 0.267..  Test Loss: 0.282..  Test Accuracy: 0.905\n",
            "Epoch: 4/15..  Training Loss: 0.241..  Test Loss: 0.286..  Test Accuracy: 0.904\n",
            "Epoch: 5/15..  Training Loss: 0.221..  Test Loss: 0.292..  Test Accuracy: 0.903\n",
            "Epoch: 6/15..  Training Loss: 0.205..  Test Loss: 0.287..  Test Accuracy: 0.905\n",
            "Epoch: 7/15..  Training Loss: 0.195..  Test Loss: 0.277..  Test Accuracy: 0.907\n",
            "Epoch: 8/15..  Training Loss: 0.185..  Test Loss: 0.288..  Test Accuracy: 0.906\n",
            "Epoch: 9/15..  Training Loss: 0.173..  Test Loss: 0.287..  Test Accuracy: 0.908\n",
            "Epoch: 10/15..  Training Loss: 0.164..  Test Loss: 0.304..  Test Accuracy: 0.905\n",
            "Epoch: 11/15..  Training Loss: 0.158..  Test Loss: 0.305..  Test Accuracy: 0.906\n",
            "Epoch: 12/15..  Training Loss: 0.152..  Test Loss: 0.292..  Test Accuracy: 0.911\n",
            "Epoch: 13/15..  Training Loss: 0.145..  Test Loss: 0.301..  Test Accuracy: 0.908\n",
            "Epoch: 14/15..  Training Loss: 0.138..  Test Loss: 0.294..  Test Accuracy: 0.913\n",
            "Epoch: 15/15..  Training Loss: 0.130..  Test Loss: 0.314..  Test Accuracy: 0.910\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTnttSgOMbY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_images = pd.read_csv(\"fashion-mnist_test.csv\")\n",
        "test_image = test_images.loc[:,test_images.columns != \"label\"].values/255\n",
        "test_dataset = torch.from_numpy(test_image)\n",
        "#test_dataset_1 = torch.utils.data.TensorDataset(test_dataset)\n",
        "new_test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 100, shuffle = False)\n",
        "results = []\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    for images in new_test_loader:\n",
        "        test = Variable(images.view(-1,1,28,28))\n",
        "        output = model(test)\n",
        "        ps = torch.exp(output)\n",
        "        top_p, top_class = ps.topk(1, dim = 1)\n",
        "        results += top_class.numpy().tolist()\n",
        "predictions = np.array(results).flatten()\n",
        "submissions=pd.DataFrame({\"id\": list(range(1,len(predictions)+1)),\n",
        "                         \"Label\": predictions})\n",
        "submissions.to_csv(\"my_submissions.csv\", index=False, header=True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}